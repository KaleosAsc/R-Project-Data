---
title: "Proyecto - Filtro de reseñas."
author: "Estefany Carolina Segura Linares  \nBrayan David Prieto Aya  \nAlejandro
  Jaramillo Vallejo\n"
date: "2025-09-08"
output:
  pdf_document: default
---

## Justificación de su importancia.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1.1 Definición del problema
En el mundo de las aplicaciones móviles, las reseñas de usuarios son un factor clave para la **reputación**, **visibilidad** y **descarga** de una app en plataformas como *Google Play* o *App Store*, entre otras.  

Sin embargo, en 2025 el crecimiento exponencial de usuarios globales trae consigo un gran desafío:

- Muchas reseñas son escritas en **múltiples idiomas**.  
- Aparecen **reseñas falsas o spam**, generadas por bots o campañas de manipulación de reputación, incluso por usuarios incentivados.  
- Estas situaciones afectan directamente la **calidad percibida** de una aplicación.  

# Problemas Generados

1. **Pérdida de confianza** en las reseñas por parte de los usuarios finales.  
2. **Competencia desleal** entre desarrolladores, donde algunos manipulan el ranking con reseñas artificiales.  
3. **Dificultad para los sistemas automáticos de moderación**, que deben procesar textos en distintos idiomas, con jergas, abreviaciones y emojis.  
4. **Impacto en los algoritmos de recomendación** de las tiendas de aplicaciones, que dependen de reseñas confiables para posicionar apps.  

# Importancia del Problema

El manejo de reseñas falsas y multilingües no solo afecta la percepción de los usuarios, sino también la **transparencia del mercado de aplicaciones móviles**, influyendo en descargas, ingresos y sostenibilidad del ecosistema digital.

## 1.2 Justificación de la importancia.

Dentro del sistema de votación de internet, las reseñas son de extrema importancia, debido a que es la primera impresión que recibe cualquier internauta ante el producto, servicio o lugar. Las reseñas falsas pueden generar un impacto malintencionado sobre el producto, lo que impide que exista un sistema de votación transparente en internet, reduciendo gradualmente la confianza de cualquier usuario ante el producto, o en su defecto, el medio por dónde lee la reseña al enaltecer o vituperar incorrectamente, pidiendo de sobremanera un filtro que pueda mitigar la problemática.

## 1.3 Preguntas de investigación o hipótesis a responder.

Si las empresas consideran la presencia de sus servicios, para mejorar su rendimientos recurrirán a reseñas spam para aumentar sus ventas de prestación de servicios.

¿Existe una relación entre la edad y la cantidad de reseñas que publica una persona con respecto a un producto?.

Si  la mayoría de usuarios del mundo están conectados a windows, será el sistema operativo que tenga más reseñas de carácter spam.

¿Existe algún tipo de relación de las reseñas de carácter spam con las aplicaciones más importantes?.

¿La dispersión es muy grande tanto para las reseñas verdaderas como de spam?.


# 2. Descripción del datataset 

## 2.2.1 Nombre y fuentes del dataset

multilingual-mobile-app-reviews-dataset-2025
“multilingual-mobile-app-reviews-dataset-2025”,Kaggle.com. Disponible en: https://www.kaggle.com/datasets/pratyushpuri/multilingual-mobile-app-reviews-dataset-2025. 

## 2.2 Variables disponibles y su significado

- **review_id**: Número identificativo de la reseña.
- **user_id**: Número identificativo del usuario.
- **app_name**: Nombre de la app desde donde se hizo la reseña.
- **app_category**: Categoría de la app desde donde se hace la reseña.
- **review_text**: Contenido de texto de la reseña.
- **review_language**: Lenguaje de la reseña.
- **rating**: Puntuación de la reseña.
- **review_date**: Fecha de publicación de la reseña.
- **verified_purchase**: Verificación de validez de compra.
- **device_type**: Tipo de dispositivo desde donde se hizo la reseña.
- **num_helpful_votes**: Número de votaciones de ayuda de la reseña por otros usuarios.
- **use_age**: Edad de usuario que realizo la reseña.
- **user_country**: País del usuario que hizo la reseña.
- **user_gender**: Género del usuario que hizo la reseña.
- **app_version**: Versión de la app desde donde se hizo la reseña.

## 2.3 Identificación de posibles problemas iniciales con los datos.

Se identifican posibles problemas iniciales en los datos, como la presencia de valores N/A (Not Available), los cuales deben ser tratados en el proceso de limpieza. Además, al ser un sistema basado en múltiples lenguajes, puede haber dificultades para establecer patrones consistentes que permitan detectar reseñas falsas, sin considerar aquellas generadas artificialmente mediante texto de relleno como Lorem Ipsum.

# 3. Análisis Exploratorio de Datos (EDA) Básico

## Importación de librerías.
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
```

## 3.1.1 Importación de dataset.

```{r}
data_reviews <- read.csv("multilingual_mobile_app_reviews_2025.csv")
```

## 3.1.2 Mostrar las primeras filas de los datos
```{r}
head(data_reviews, 5)
```

## 3.1.3 Identificar cantidad de filas y columnas.

```{r}
dim(data_reviews)
```
El dataset presenta 2514 fila con 15 columnas.

## 3.2.1 Verificar el tipo de variables (numéricas o categóricas).

# Variables Cuantitativas (numéricas)
- **rating**
- **num_helpful_votes**
- **user_age**

# Variables Cualitativas (Categoricas)
- **review_id**
- **app_name***
- **user_id**
- **app_category**
- **review_text**
- **review_language**
- **review_date**
- **verified_purchase**
- **device_type**
- **user_country**
- **user_gender**
- **app_version**

# 3.2.2 Calcular la media, mediana y desviación estándar de las variables numéricas principales.

```{r}
cat("=== Estadísticas de rating ===\n")
cat("Media: ", mean(data_reviews$rating, na.rm = TRUE), "\n")
cat("Mediana: ", median(data_reviews$rating, na.rm = TRUE), "\n")
cat("Desviación estándar: ", sd(data_reviews$rating, na.rm = TRUE), "\n\n")

cat("=== Estadísticas de user_age ===\n")
cat("Media: ", mean(data_reviews$user_age, na.rm = TRUE), "\n")
cat("Mediana: ", median(data_reviews$user_age, na.rm = TRUE), "\n")
cat("Desviación estándar: ", sd(data_reviews$user_age, na.rm = TRUE), "\n\n")

cat("=== Estadísticas de num_helpful_votes ===\n")
cat("Media: ", mean(data_reviews$num_helpful_votes, na.rm = TRUE), "\n")
cat("Mediana: ", median(data_reviews$num_helpful_votes, na.rm = TRUE), "\n")
cat("Desviación estándar: ", sd(data_reviews$num_helpful_votes, na.rm = TRUE), "\n")
```

# 3.2.3 Obtener frecuencias de variables categóricas.

```{r}
categoricas <- c("app_name", "app_category", "review_language",
                 "verified_purchase", "device_type", 
                 "user_gender", "user_country")

for (var in categoricas) {
  cat("\n=== Frecuencias de", var, "===\n")
  
  freq <- data_reviews %>%
    count(.data[[var]]) %>%
    mutate(prop = n / sum(n))
  
  print(freq)
}
```



## 3.3.1 Contar cuántos valores faltantes hay por variable (sin necesidad de imputarlos todavía).

```{r}
null_data <- colSums(is.na(data_reviews))
print(null_data)

```

# 4.Revisión bibliográfica.

## 4.1 Estudios previos relacionados con el problema.
- Stanley Munga Richard Mathenge Josphat Karani Nicholus Muriithi, “Spam Detection in Emails Using Machine Learning Techniques: A Review”, Researchgate.net, 3- September 2024. Disponible en: https://www.researchgate.net/publication/391203243_Spam_Detection_in_Emails_Using_Machine_Learning_Techniques_A_Review.

- N. Jindal y B. Liu, “Opinion spam and analysis”, en Proceedings of the international conference on Web search and web data mining - WSDM ’08, 2008, p. 219.

## 4.2 Métodos usados en investigaciones similares.

La literatura reciente (2022–2025) muestra una evolución clara en los enfoques utilizados para detectar reseñas falsas en múltiples idiomas.  
De todos los métodos, destacan tres como los más recurrentes y efectivos:

---

## 1. Transformadores multilingües (ej. XLM-R, mBERT, MuRIL)

- **Qué son**: modelos basados en *transformers* entrenados en decenas de lenguas, capaces de generar representaciones contextuales universales.  
- **Cómo funcionan**: procesan el texto directamente en su idioma original, evitando pérdidas de señal al traducir.  
- **Ventajas**:
  - Capturan semántica y estilo en paralelo.  
  - Permiten *transfer learning* entre idiomas.  
  - Suelen liderar los benchmarks multilingües.  
- **Limitaciones**:
  - Requieren bastante cómputo.  
  - Sesgos culturales en idiomas minoritarios.  

---

## 2. Modelos híbridos (texto + metadatos de usuario/comportamiento)

- **Qué son**: arquitecturas que combinan análisis del texto con señales externas (frecuencia de reseñas, timestamps, historial del usuario, verified purchase).  
- **Cómo funcionan**: el texto se procesa con embeddings o transformers, y se fusiona con features tabulares en un clasificador (p. ej. redes neuronales, XGBoost).  
- **Ventajas**:
  - Más robustos ante reseñas generadas por IA.  
  - Permiten detectar patrones de spam organizados.  
- **Limitaciones**:
  - No siempre hay metadatos disponibles.  
  - Requieren integración de distintas fuentes de datos.  

---

## 3. Métodos basados en grafos (Graph Neural Networks)

- **Qué son**: técnicas que representan la relación entre usuarios, productos y reseñas como un grafo.  
- **Cómo funcionan**: los nodos (usuarios, reseñas, productos) se conectan, y la red neuronal de grafos aprende a detectar patrones sospechosos de colusión.  
- **Ventajas**:
  - Muy útiles para grandes plataformas (Amazon, Yelp, TripAdvisor).  
  - Detectan redes organizadas de spam que otros modelos pasan por alto.  
- **Limitaciones**:
  - Necesitan datos estructurados a gran escala.  
  - Costosos de implementar en entornos pequeños.  

# 5.Plan de trabajo.

## 5.1 Metodología general a seguir.

Metodología Propuesta (Naive Bayes simplificado)

## 1. Diseño de la investigación  
El proyecto busca detectar reseñas falsas en un dataset multilingüe.  
Se usará el clasificador **Naive Bayes**, aprovechando tanto el texto de la reseña como algunas variables adicionales.  

---

## 2. Conjunto de datos  
- Dataset entregado por el curso/proyecto.  
- No incluye etiquetas de *real/falsa*, por lo que será necesario **categorizarlas manualmente** según reglas simples.  

---

## 3. Preparación de los datos  
- Convertir todo el texto a minúsculas.  
- Quitar signos de puntuación y *stopwords* (palabras comunes como *de, la, the, and*).  
- Tokenizar (dividir en palabras).  
- Representar texto con **Bolsa de Palabras (BoW)** o **TF-IDF**.  
- Variables adicionales como `verified_purchase`, `rating`, `device_type` o `country` se codifican en valores numéricos o categóricos.  

---

## 4. Modelo de clasificación  
- Se usa **Naive Bayes Multinomial** (adecuado para texto).  
- El modelo aprende a partir de las probabilidades de cada palabra/variable en reseñas reales o falsas.  
- Se aplica suavizado de Laplace para evitar problemas con palabras nuevas.  

---

## 5. Entrenamiento y validación  
- División de datos: 70% entrenamiento, 30% prueba.  
- Evaluación mediante:  
  - **Accuracy** (exactitud general).  
  - **Precision y Recall** (qué tan bien detecta reseñas falsas sin confundir reales).  
  - **F1-score** (balance entre precisión y recall).  

---

## 6. Aporte esperado  
- Un dataset con etiquetas *real/falsa* definido por el equipo investigador.  
- Validación de la utilidad de **Naive Bayes** en la detección de reseñas falsas.  
- Reflexión sobre las limitaciones del enfoque y posibles mejoras en proyectos futuros.  



## 5.2 Cronograma de trabajo 
```{r}
library(ggplot2)

# Datos del cronograma
cronograma <- data.frame(
  fase = c("Diseño de la investigación",
           "Conjunto de datos",
           "Preparación de los datos",
           "Modelo de clasificación",
           "Entrenamiento y validación",
           "Análisis y resultados",
           "Informe final"),
  inicio = as.Date(c("2025-09-15","2025-09-16","2025-09-17",
                     "2025-10-13","2025-10-27","2025-11-10","2025-11-17")),
  fin    = as.Date(c("2025-09-21","2025-09-28","2025-10-12",
                     "2025-10-26","2025-11-09","2025-11-16","2025-11-23"))
)

# Gráfico de Gantt con divisiones de fases
ggplot(cronograma, aes(x = inicio, xend = fin, y = fase, yend = fase)) +
  geom_segment(size = 5, color = "steelblue") +
  # Líneas divisorias horizontales entre fases
  geom_hline(yintercept = 1:length(cronograma$fase) + 0.5,
             linetype = "solid", color = "gray70", size = 0.5) +
  labs(title = "Cronograma-Trabajo: Detección de Reseñas Falsas",
       x = "Fecha", y = "Fases") +
  scale_x_date(date_breaks = "3 days", date_labels = "%d-%b") +
  theme_minimal(base_size = 12) +
  theme(axis.text.y = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(face = "bold", hjust = 0.5))
```


## 5.3 Herramientas y lenguajes de programación.

**Lenguaje R**

R como lenguaje cumple un factor decisivo para la realización del proyecto, sobre todo para el análisis de datos.Según su definición R es una sistema para la computación estadística y gráficas enfocado a un lenguaje de programación para generación de gráficas optimizadas y limpieza de errores[1].

Además de su diversidad de elementos que ofrece para el tratamiento de los datos según las necesidades del proyecto, consolidado por su vasto dominio de paquetes que tienen dominios como la estadística, aprendizaje automatizado, visualización de datos y análisis de series de tiempo definido bajo una red comprensiva de archivos (CRAN) con alrededor 18000 librerías desarrollada por la comunidad[2].

**RStudio**

Posterior al entendimiento del lenguaje R, destacamos que Rstudio como editor de código abierto, que nos permite escribir citaciones, visualizar la generación de código y el comportamiento de las variables de datos involucradas[3].

Con características destacables como su consola, editor de scripts, un ambiente de panel que permite observar las variables afectadas en tiempo real, panel de historia que muestra los comando ejecutados y un espacio de proyectos para guardar el trabajo en conjunto a la solución de un proyecto[2].

**RMarkdown**

Por último, para documentación del proceso de tratamiento de datos por la identificación de spam por medio de la ecuación Naive Bayes en reseñas, nos permite formatear las sustentaciones del código por medio de markdown para indicar la estética de los textos implícitos en los proceso escrito del proyecto, diferente a aplicaciones como word[4].

Facilitado por su portabilidad, y cambios de las aplicaciones  de edición en código. RMarkdown es una herramienta de valor para el ámbito investigativo para la preservación de conocimiento en el tiempo con adaptación estandarizada que ofrece markdown para libros, tesis de universidades[4], etc. 

# 6. Expectativas y retos.

## 6.1 Posibles dificultades y estrategias para resolverlas.

*Dificultad*: Poca claridad de palabras claves que nos permiten identificar un comportamiento de spam para una contraseña.

*Estrategia*: Investigación  de proyectos previos que nos indiquen que palabras clases influyen en las reseñas podrían ser consideradas spam o no.

*Dificultad*: Presencia de datos nulos en la variable review_text que no faciliten el procesamiento de clasificación de las reseñas, considerado como un dato atípico que puede entorpecer los cálculos de probabilidad o verosimilitud de spam.

*Estrategia*: Limpieza de datos de datos que sean nulos, para no permitir el entorpecimiento del cálculo de palabras claves para Naive Bayes.

*Dificultad*: Presencia de otras variables que tengan relación con el comportamiento de spam presentado en el dataset.

*Estrategia*: Identificación relación entre variables por medio de modelos estadísticos complementarios que nos permitan definir relaciones con el spam.

*Dificultad*: Definir porcentaje de éxito de clasificación spam por medio de la ecuación Naive Bayes.

*Estrategia*: Definición de KPI o parámetro evaluables que midan el estado del arte del modelo para identificar spam.

*Dificultad*:Presencia de valores atípicos diferentes review_text que afecten la detección de spam.

*Estrategia*: Definición de procesos de análisis de relación(sea de cualitativo o cuantitativo) que definan su efecto en la generación de reseñas de spam.

# 7. Conclusión preliminar

## 7.1  Resumen del planteamiento del problema y hallazgos iniciales.

En las aplicaciones móviles, las reseñas de los usuarios son muy importantes porque influyen en la reputación, descargas y visibilidad de una app. Sin embargo, hoy en día existen dos grandes problemas: la gran cantidad de reseñas en diferentes idiomas y la presencia de reseñas falsas o manipuladas.

Los hallazgos iniciales muestran que estas situaciones afectan la calidad percibida de las aplicaciones y el correcto funcionamiento de los sistemas de recomendación en las tiendas digitales.

Aplicar la ecuación de Naive Bayes para la clasificación de spam en reseñas de las aplicaciones móviles principales en el mundo, por otra parte solucionar problemas con la claridad de los datos dentro del dataset para evitar el dispersión en la clasificación de reseñas y del mismo modo encontrar algún tipo de relación con las demás variables presentables dentro del dataset que puedan influir en el proceso de clasificación.

Establece el reconocimiento de la variables, además de la que compone a reseña como números identificativos del usuario, edad de los usuarios, sistema operativo, tipo de dispositivo, categoría de aplicación entre otros que pueden ser de ayuda para ver una relación entre la variables y su comportamiento con respecto a la reseñas.

Identificar un conjunto de dificultades como datos nulos, atípicos y medidas evaluativas de efectividad para proponer un serie de estrategias que nos permiten medir el alcance de funcionamiento del sistema para discernir el impacto de la reseña de carácter verdadero y de spam en el mundo real y su impacto en el rendimiento de los servicios aplicativos.

Comprender la sustentación técnica como lenguajes de programación con enfoque estadísticos, que nos permitan aplicar la ecuación Niave Bayes con gráficas estadísticas que para fácil visualización, además de un gran complejo de librerías de código abierto que facilitan el sistema de análisis de desarrollo.

Considerar que la calidad del dataset influye de manera crítica en los resultados. Variables como verificación de compra, rating o país muestran correlaciones claras con la autenticidad de las reseñas, aportando valor en la identificación de patrones fraudulentos.



# Referencias

[1] GeeksforGeeks, “Pros and Cons of R Programming Language,” GeeksforGeeks, Jul. 23, 2025. https://www.geeksforgeeks.org/r-language/pros-and-cons-of-r-programming-language/

[2] R Core Team, “R Language Definition.”https://cran.r-project.org/doc/manuals/r-release/R-lang.html

[3] GeeksforGeeks, “RStudio Tutorial,” GeeksforGeeks, Jul. 23, 2025. https://www.geeksforgeeks.org/r-language/rstudio-tutorial/

[4] “Getting started | Markdown Guide.” https://www.markdownguide.org/getting-started/

[5] M. I. Ragab, E. Hussein Mohamed, and W. Medhat, “Multilingual Propaganda Detection: Exploring Transformer-Based Models mBERT, XLM-RoBERTa, and mT5,” ACL Anthology, 2025. https://aclanthology.org/2025.nakbanlp-1.9

[6] Anonymous, “A deep learning approach for detecting fake reviewers: Exploiting reviewing behavior and textual information,” Decision Support Systems, vol. 166, p. 113911, 2023. https://www.sciencedirect.com/science/article/abs/pii/S0167923622001828

[7] L.-C. Cheng, Y. T. Wu, C.-T. Chao, and J.-H. Wang, “Detecting fake reviewers from the social context with a graph neural network method,” Decision Support Systems, 2024. https://ouci.dntb.gov.ua/en/works/4yXaNdp7

[8] Anonymous, “Detecting review fraud using metaheuristic graph neural networks,” International Journal of Information Technology, 2024. https://link.springer.com/article/10.1007/s41870-024-01896-w
