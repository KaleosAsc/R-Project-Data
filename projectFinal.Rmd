---
title: "Proyecto - Filtro de rese√±as."
author: "Estefany Carolina Segura Linares  \nBrayan David Prieto Aya  \nAlejandro
  Jaramillo Vallejo\n"
date: "2025-10-28"
output:
  pdf_document: default
---

# 1. Introducci√≥n
- Breve presentaci√≥n del proyecto.
- Contextualizaci√≥n del problema y su relevancia.

La influencia del internet ha cambiado la dinamicas de la relevancia de un servicio, las personas denominados en un rol de usuarios buscan la buena imagen a la hora descargar algun tipo de aplicaci√≥n por medio de las rese√±as que validan la experiencia del acceso a este mismo para tomar una decisi√≥n, en este caso las rese√±as positivas pueden influir en prestigio asociado al negocio.

Por eso, se pueden dar sponsors de "opinion spamming" donde se patrocinan rese√±as fraudulentas para promover aplicaciones o en caso de compotencia desleal, para desvaluar una aplicaci√≥n de otro negocio por el √°rea de un servicio. 

De esta manera, aplicar sistemas de mineria de datos para evaluar no veridicas rese√±as positivas o en orden de probar un competencia justa dentro del negocio de las aplicaciones que se quieren da√±ar su reputaci√≥n, por esto mismo genera procesos de datos que permiten dar una resoluci√≥n real a los usuarios o identificar que tipo de estructuras se usan en ese tipo de practicas.


# 2. Justificaci√≥n
La importancia del estudio de los datos en este problema radica en comprender a fondo qu√© variables son realmente relevantes para el sistema de clasificaci√≥n. No todas las caracter√≠sticas presentes en el conjunto de datos aportan informaci√≥n √∫til, y un an√°lisis preliminar permite identificar aquellas que influyen directamente en la detecci√≥n y clasificaci√≥n de las rese√±as. Este proceso no solo evita el ruido dentro del modelo, sino que tambi√©n mejora la precisi√≥n y eficiencia del algoritmo, al centrarse en los patrones ling√º√≠sticos y sem√°nticos m√°s representativos. Adem√°s, el estudio de los datos permite detectar sesgos, inconsistencias o distribuciones desbalanceadas, factores que pueden comprometer la capacidad del sistema para generalizar correctamente ante nuevas rese√±as. En conjunto, este an√°lisis es un paso fundamental para garantizar la calidad, coherencia y validez del modelo de clasificaci√≥n.

- Valor agregado del an√°lisis realizado.

# 3. Objetivos
- **General**: Enunciar el objetivo principal del proyecto.

Generar un sistema de mineria de datos, que aplica el algoritmo de Naive Bayes para determinar y/o de rese√±as spam multilenguaje para aplicaciones. 

- **Espec√≠ficos**: Al menos tres objetivos que detallen las metas t√©cnicas del an√°lisis.

Identificar las palabras o t√©rminos con mayor peso predictivo dentro de las rese√±as SPAM y no-SPAM, aportando interpretabilidad al modelo.

Analizar los patrones de comportamiento de los usuarios que generan rese√±as SPAM, identificando tendencias seg√∫n el sistema operativo y otras variables demogr√°ficas o t√©cnicas relevantes.

Dise√±ar un dashboard interactivo que permita visualizar la tendencia de rese√±as en funci√≥n de la app seleccionada.


# 4. Fases del Proceso KDD (documentadas seg√∫n su aplicaci√≥n)

## 4.1 Dominio del problema
- Describir el contexto del fen√≥meno o situaci√≥n a analizar.

Dentro de la competici√≥n digital que se presenta hoy dentro de los negocios digitales, las rese√±as se han vuelto una forma bastante importante para acceder a un servicio digital(app), siendo un actividad tan importante para la posici√≥n de marca de un negocio que opta por este medio las rese√±as determinan su puesto frente a la competenecia y el mercado.

Debido a esto se puede presentar situaciones donde la rese√±as son patrocinadas en una inflaci√≥n por spam para posicionar la marca de app o utilizar la tecnica para desprestigiar a los competidores genera una duda de la veracidad de los servicios digitales.

El modelo presente busca evaluar y predecir que tipo de contenido en rese√±a multilenguaje determina que una rese√±a en una aplicaci√≥n es de tipo spam, por medio del algoritmo de Naive Bayes con su especializaci√≥n en clasificar nos permite discernir en el comportamiento de competenecia desleal en linea.




- Formular preguntas de investigaci√≥n o hip√≥tesis que orienten la miner√≠a de datos.
- Identificar la relevancia del problema y su impacto en la toma de decisiones.

La relevancia del problema se centra en la necesidad de asegurar la autenticidad de las rese√±as en plataformas digitales. La presencia de rese√±as falsas o SPAM afecta la credibilidad de los sistemas de valoraci√≥n y puede distorsionar la percepci√≥n que los usuarios tienen sobre un producto o servicio.

Detectar y clasificar adecuadamente este tipo de rese√±as permite mantener la confianza del usuario y proteger la reputaci√≥n de las aplicaciones. Adem√°s, contribuye a generar entornos digitales m√°s transparentes y fiables para la toma de decisiones.

El impacto en la toma de decisiones es significativo, ya que los desarrolladores y administradores pueden identificar patrones an√≥malos, optimizar estrategias de marketing y mejorar la calidad de sus servicios. En conjunto, el an√°lisis de rese√±as se convierte en una herramienta clave para fortalecer la gesti√≥n y credibilidad de las plataformas.

## 4.2 Selecci√≥n de Datos
- Describir la fuente de los datos (base utilizada, variables disponibles).

- Seleccionar las variables relevantes y justificar su elecci√≥n.

Para la alimentaci√≥n y elecci√≥n del dataset se tomaran las variables 
- **review_text** : El contenido de texto de la rese√±a asociada a la aplicaci√≥n que contiene palabras o mensajes que indiquen spam.

- **rating** : Puntuaci√≥n de la aplicaci√≥n para valoraci√≥n si presenta algun tipo de inflaci√≥n.

- **verified_purchase**: Variable que verifica si una rese√±a ha sido verificada por validez, tal vez las cantidades esten infladas para el posicionamiento de la aplicaci√≥n.

- Indicar las variables eliminadas (por redundancia, irrelevancia o datos faltantes excesivos).

Las variables eliminadas fueron:

- **review_id**: Identificador √∫nico de cada rese√±a; no aporta informaci√≥n √∫til al modelo, ya que su funci√≥n es √∫nicamente de indexaci√≥n.

- **user_id**: Identificador √∫nico del usuario; no contribuye a la clasificaci√≥n ni al an√°lisis, y su inclusi√≥n puede generar ruido o riesgo de sesgo por usuario.

- **num_helpful_votes**: N√∫mero de votos √∫tiles que recibi√≥ una rese√±a; es un valor externo al contenido y puede estar influenciado por la visibilidad o popularidad, no por la autenticidad del texto.

- **user_gender**: G√©nero del usuario; presenta una proporci√≥n significativa de datos faltantes y no tiene un impacto directo sobre el contenido o tipo de rese√±a.

- **app_version**: Versi√≥n de la aplicaci√≥n rese√±ada; no afecta el an√°lisis sem√°ntico ni la clasificaci√≥n de rese√±as, por lo que no es relevante para el modelo.

## 4.3 Limpieza de Datos
- Valores faltantes: especificar la estrategia usada (eliminaci√≥n, imputaci√≥n, estimaci√≥n).

Imputaci√≥n de **User_country**
Para este caso, se decidi√≥ imputar el pa√≠s en funci√≥n del idioma de la rese√±a, utilizando una relaci√≥n directa entre review_language y el pa√≠s donde dicho idioma es predominante. Este m√©todo de imputaci√≥n basada en reglas permite mantener la coherencia contextual de los datos, evitando introducir ruido aleatorio o sesgos significativos.
Solo se aplic√≥ la imputaci√≥n cuando la asociaci√≥n entre idioma y pa√≠s era clara y dominante (por ejemplo, japon√©s con Jap√≥n, portugu√©s con Brasil). En idiomas de uso global, como ingl√©s o espa√±ol, se evit√≥ imputar para no sobrerrepresentar regiones.

Adem√°s de eso, se eliminaron los valores restantes no clasificados, que representaron alrededor de 20 campos, un valor √≠nfimo dentro del total del dataset.

Eliminaci√≥n de valores faltantes en **user_rating**
Los registros sin valoraci√≥n fueron eliminados porque no aportan una medida cuantificable para el an√°lisis o entrenamiento del modelo. Dado que representan un porcentaje muy bajo (alrededor del 1.2% de los datos totales), su eliminaci√≥n no afecta de forma significativa la representatividad del conjunto.

Imputar estos valores habr√≠a introducido varianza artificial y podr√≠a distorsionar la distribuci√≥n del objetivo principal del modelo

Eliminaci√≥n de valores faltantes en **review_text**
Las rese√±as sin texto fueron eliminadas ya que no contienen informaci√≥n sem√°ntica para el an√°lisis de texto o la clasificaci√≥n basada en lenguaje natural. Aunque algunas aplicaciones permiten dejar una valoraci√≥n sin comentario, en este contexto anal√≠tico el texto es esencial para los modelos de clasificaci√≥n y detecci√≥n de spam.
El n√∫mero de eliminaciones fue m√≠nimo (aproximadamente otro 1.2%), por lo que esta decisi√≥n mejora la calidad del dataset sin comprometer su tama√±o.

- Errores e inconsistencias: documentar correcciones, duplicados o errores tipogr√°ficos.

El conjunto de datos presentaba desde su origen un alto nivel de calidad y consistencia, sin requerir procesos de depuraci√≥n significativos. Las variables se encontraban correctamente estructuradas, con tipos de datos apropiados, sin presencia de valores at√≠picos evidentes, duplicados ni errores de codificaci√≥n.

En consecuencia, no fue necesario aplicar procedimientos adicionales de limpieza, imputaci√≥n o transformaci√≥n m√°s all√° de las comprobaciones b√°sicas de integridad. La informaci√≥n se encontraba organizada y libre de anomal√≠as, lo cual facilit√≥ directamente su uso para las etapas de an√°lisis exploratorio y modelado.

Este escenario permiti√≥ conservar la estructura original del dataset, garantizando la trazabilidad y autenticidad de los datos, manteniendo as√≠ la fidelidad respecto a su fuente y su interpretaci√≥n anal√≠tica.

- Outliers: describir el m√©todo de detecci√≥n (boxplot, z-score, etc.) y las decisiones tomadas.

## 4.4 Transformaci√≥n de Datos
- Normalizaci√≥n o estandarizaci√≥n de variables num√©ricas.

En este caso no se aplic√≥ ning√∫n proceso de normalizaci√≥n o estandarizaci√≥n debido a que la √∫nica variable num√©rica relevante **rating** ya se encuentra expresada en una escala limitada y uniforme (0 a 5). Esta escala es inherentemente comparable y est√° dise√±ada para representar de forma directa el nivel de satisfacci√≥n del usuario, por lo que no requiere ajustes adicionales.

Adem√°s, el modelo seleccionado para el an√°lisis, Naive Bayes, no depende de magnitudes o distancias entre variables, sino de distribuciones de probabilidad. Por tanto, modificar la escala de rating no aportar√≠a mejoras en la capacidad predictiva del modelo ni en la consistencia de los resultados.

- Codificaci√≥n de variables categ√≥ricas (one-hot o label encoding).
- Creaci√≥n de nuevas variables derivadas relevantes para el modelo.
- Reducci√≥n de dimensionalidad, si aplica (PCA u otras t√©cnicas).
- Mostrar fragmentos de c√≥digo en R y comparaciones ‚Äúantes y despu√©s‚Äù de las tablas.

## 4.5 Miner√≠a de Datos
- Seleccionar y justificar el algoritmo o t√©cnica empleada (clasificaci√≥n, regresi√≥n, clustering, etc.).
- Describir la divisi√≥n de datos (entrenamiento y prueba).
- Presentar las m√©tricas de evaluaci√≥n (Accuracy, F1-Score, MAE, etc.).
- Incluir visualizaciones que respalden los resultados del modelo.

## 4.6 Interpretaci√≥n y Evaluaci√≥n
- Analizar cr√≠ticamente los resultados obtenidos.
- Validar el conocimiento descubierto frente a las hip√≥tesis y objetivos planteados.
- Evaluar el valor del conocimiento extra√≠do para el contexto del problema.

# 5. Conclusiones
- Sintetizar los principales hallazgos.
- Reflexionar sobre el proceso completo y sus limitaciones.
- Proponer posibles trabajos futuros o mejoras.

# 6. Anexos
- Gr√°ficos, tablas, fragmentos de c√≥digo, resultados adicionales que complementen el an√°lisis.

```{r}
install.packages("httr")
install.packages("jsonlite")
install.packages("cld2")
install.packages("dotenv")
```
```{r}
library(readr)
library(dplyr)
library(httr)
library(jsonlite)
library(purrr)
library(rlang) 
library(cld2)
library(dotenv)
```

```{r}
multilingual_mobile_app_reviews_2025 <- read_csv("multilingual_mobile_app_reviews_2025.csv")
View(multilingual_mobile_app_reviews_2025)
```

```{r}
# Contar valores vac√≠os en todo el dataset
colSums(is.na(multilingual_mobile_app_reviews_2025))
```

```{r}
Copia_Datos_Limpios <- multilingual_mobile_app_reviews_2025
Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  select(-review_id, -num_helpful_votes, -user_id, -user_gender, -app_version)
colSums(is.na(Copia_Datos_Limpios))
```

```{r}
# Filtro general para cualquier variable
filtro_user_country <- Copia_Datos_Limpios %>% filter(is.na(user_country))
filtro_review_text  <- Copia_Datos_Limpios %>% filter(is.na(review_text))
filtro_rating       <- Copia_Datos_Limpios %>% filter(is.na(rating))
```

```{r}
Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  mutate(
    user_country = case_when(
      review_language == "es" ~ "Spain",          # Spanish
      review_language == "pt" ~ "Brazil",         # Portuguese
      review_language == "ja" ~ "Japan",          # Japanese
      review_language == "hi" ~ "India",          # Hindi
      review_language == "ko" ~ "South Korea",    # Korean
      review_language == "zh" ~ "China",          # Chinese
      review_language == "de" ~ "Germany",        # German
      review_language == "fr" ~ "France",         # French
      review_language == "it" ~ "Italy",          # Italian
      review_language == "ru" ~ "Russia",         # Russian
      TRUE ~ user_country                         # Keep original if no match
    )
  )

Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  filter(!is.na(rating))

Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  filter(!is.na(review_text))

Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  filter(!is.na(user_country))

colSums(is.na(Copia_Datos_Limpios)[, c("user_country", "review_text", "rating")])
```

```{r}
sapply(Copia_Datos_Limpios,class)
```
```{r}
language <- unique(Copia_Datos_Limpios$review_language)
typeof(language)

```
```{r}
# Asegurar que review_language sea texto
Copia_Datos_Limpios$review_language <- as.character(Copia_Datos_Limpios$review_language)

# Reemplazar 'zh' por 'zh-Hans' (chino simplificado)
Copia_Datos_Limpios$review_language[Copia_Datos_Limpios$review_language == "zh"] <- "zh-Hans"

# Verificar valores √∫nicos despu√©s de la correcci√≥n
unique(Copia_Datos_Limpios$review_language)

```
```{r}
translate_review_text <- function(text, target = "en", key, endpoint, region = "global") {
  print(text)
  if (is.na(text) || nchar(text) == 0) print("Value null")
  
  url <- paste0(endpoint, "translate?api-version=3.0&to=", target)
  body <- list(list(Text = text))
  
  response <- POST(
    url,
    add_headers(
      `Ocp-Apim-Subscription-Key` = key,
      `Ocp-Apim-Subscription-Region` = region,
      `Content-Type` = "application/json"
    ),
    body = toJSON(body, auto_unbox = TRUE)
  )
  
  
  
  # Manejo de errores
  if (status_code(response) != 200) {
    warning(paste("Error:", content(response, "text", encoding = "UTF-8")))
    return(NA_character_)
  }
  
  result <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
  # cat("üì¶ Resultado bruto de la API:\n", 
  #   jsonlite::toJSON(result, pretty = TRUE, auto_unbox = TRUE), 
  #   "\n\n")
  # str(result)
  translated_text <- result$translations[[1]]$text
 # cat("‚úÖ Traducido:", translated_text, "\n\n--- Fin impresi√≥n OK ---\n\n")

  return(translated_text)
}
```

```{r}
# --- Configuraci√≥n Azure ---
#load_dot_env()
#key <- Sys.getenv("AZURE_KEY")
endpoint <- "https://api.cognitive.microsofttranslator.com/"
region <- "global"

# --- Subconjunto de prueba ---
# Copia_Datos_Limpios_test <- head(Copia_Datos_Limpios, 10)

# --- Aplicar traducci√≥n solo sobre las columnas necesarias ---
Copia_Datos_Limpios$translated <- pmap_chr(
  list(Copia_Datos_Limpios$review_text),
  function(review_text) {
    response <- translate_review_text(
      text = review_text,
      target = "en",
      key = key,
      endpoint = endpoint,
      region = region
    )
    
    if (is.null(response) || length(response) == 0) {
      return(NA_character_)
    } else {
      print(response)  # para ver progreso
      return(enc2utf8(as.character(response)))
    }
  }
)
```
- marcar como Spam para frases que se repiten 

```{r}
Copia_Datos_Limpios$is_duplicated <-
  duplicated(Copia_Datos_Limpios$translated) |
  duplicated(Copia_Datos_Limpios$translated, fromLast = TRUE)

Copia_Datos_Limpios$spam_verified <- ifelse(Copia_Datos_Limpios$is_duplicated, "spam", "ham")
View(Copia_Datos_Limpios)
```
-Bolsa de palabras validas para una rese√±a
```{r}
# Bolsa de palabras v√°lidas para rese√±as
valid_words <- c(
  "great", "good", "excellent", "amazing", "love", "helpful", "easy", "fast",
  "quality", "recommend", "happy", "satisfied", "improved", "useful", "perfect",
  "bad", "terrible", "disappointed", "problem", "issue", "broken", "slow",
  "update", "feature", "service", "support", "interface", "design", "experience",
  "download", "install", "upgrade", "bug", "error", "crash", "fix", "solution"
)
```
-Funci√≥n para evaluaci√≥n de texto valido
```{r}
# Funci√≥n para evaluar si un texto es v√°lido
is_valid_review <- function(text) {
  # Manejar valores nulos o vac√≠os
  if (is.na(text) || text == "" || nchar(trimws(text)) == 0) {
    return(FALSE) # Texto vac√≠o o nulo no es v√°lido
  }
  
  # Convertir el texto a min√∫sculas para hacer la comparaci√≥n insensible a may√∫sculas/min√∫sculas
  text_lower <- tolower(as.character(text))
  
  # Verificar si alguna palabra v√°lida aparece en el texto
  has_valid_word <- any(sapply(valid_words, function(word) grepl(paste0("\\b", word, "\\b"), text_lower)))
  
  return(has_valid_word)
}
```
- Evaluaci√≥n del dataset
```{r}
Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  mutate(
    spam_verified = case_when(
      spam_verified != "spam" & 
        detect_language(translated) == "en" & 
        is_valid_review(translated) ~ "ham", # Ham si no es spam, est√° en ingl√©s y contiene palabras v√°lidas
      
      spam_verified != "spam" & 
        detect_language(translated) == "en" & 
        !is_valid_review(translated) ~ "spam", # Spam si no es spam, est√° en ingl√©s pero no contiene palabras v√°lidas
      
      TRUE ~ spam_verified # Mantener el valor original si no se cumplen las condiciones anteriores
    )
  )
```

- Lista de lenguaje asociado al pa√≠s
```{r}
# Funci√≥n para obtener el idioma t√≠pico de un pa√≠s
get_language_from_country <- function(country) {
  # Mapeo de pa√≠ses a c√≥digos de idioma (basado en tu lista)
  country_to_language <- c(
    "China" = "zh-Hans",          # Chino simplificado
    "Russia" = "ru",              # Ruso
    "Spain" = "es",               # Espa√±ol
    "India" = "hi",               # Hindi (tambi√©n podr√≠a ser "en" si se usa ingl√©s com√∫nmente)
    "South Korea" = "ko",         # Coreano
    "Australia" = "en",           # Ingl√©s
    "Japan" = "ja",               # Japon√©s
    "France" = "fr",              # Franc√©s
    "Italy" = "it",               # Italiano
    "Germany" = "de",             # Alem√°n
    "Vietnam" = "vi",             # Vietnamita
    "Turkey" = "tr",              # Turco
    "Thailand" = "th",            # Tailand√©s
    "Brazil" = "pt",              # Portugu√©s
    "Nigeria" = "en",             # Ingl√©s (oficial y ampliamente usado)
    "United States" = "en",       # Ingl√©s
    "Bangladesh" = "bn",          # Bengal√≠
    "Canada" = "en",              # Ingl√©s (tambi√©n podr√≠a ser "fr" para franc√©s en Quebec)
    "Indonesia" = "id",           # Indonesio
    "Mexico" = "es",              # Espa√±ol
    "Malaysia" = "ms",            # Malayo
    "Pakistan" = "ur",            # Urdu (tambi√©n podr√≠a ser "en" si se usa ingl√©s com√∫nmente)
    "Philippines" = "fil",        # Filipino
    "United Kingdom" = "en"       # Ingl√©s
  )
  
  # Devolver el idioma correspondiente al pa√≠s
  return(country_to_language[country])
}
```
- Funci√≥n detector de lenguaje
```{r}
# Funci√≥n para detectar el idioma de un texto
detect_language <- function(text) {
  if (is.na(text) || text == "") {
    return(NA) # Manejar valores nulos o vac√≠os
  }
  
  # Detectar el idioma usando cld2
  detected <- cld2::detect_language(text)
  return(detected) # Devolver el c√≥digo del idioma detectado
}
```


- Se verifica que el lenguaje que se maneja es el mismo al del pa√≠s(esta opci√≥n es opcional porque reduce los ham demasiado)

```{r}
Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  mutate(
    detected_language = sapply(review_text, detect_language), # Detectar el idioma del texto
    spam_verified = case_when(
      spam_verified == "ham" & 
        (
          review_language != get_language_from_country(user_country) | # Idioma declarado no coincide con el pa√≠s
          detected_language != get_language_from_country(user_country) # Idioma detectado no coincide con el pa√≠s
        ) ~ "spam", # Marcar como spam si no coincide el idioma
      TRUE ~ spam_verified # Mantener el valor original si no se cumplen las condiciones
    )
  ) %>%
  select(-detected_language) # Eliminar columna auxiliar si no es necesaria
```
- Muestra los valores que se consideran rese√±as verdaderas
```{r}
unique(Copia_Datos_Limpios$spam_verified)
values_verified <- Copia_Datos_Limpios %>% filter(spam_verified == "ham")
View(values_verified)
```
- Verifica que idioma toma para los casos lorem ipsum
```{r}
detect_language("Eius odio facilis fuga distinctio eaque.")
```
- Funci√≥n para evaluar si un texto esta en latin y por lo tanto es lorem ipsum
```{r}
## Funci√≥n para detectar si un texto es lat√≠n (vectorizada)
is_latin <- function(text) {
  # Manejar valores nulos o vac√≠os (vectorizado)
  if (all(is.na(text)) || all(text == "") || all(nchar(trimws(text)) == 0)) {
    return(rep(FALSE, length(text))) # Devolver un vector de FALSE del mismo tama√±o
  }
  
  # Lista de palabras clave y sufijos t√≠picos del lat√≠n
  latin_keywords <- c(
    "quis", "doloribus", "consequuntur", "perspiciatis", 
    "tempora", "assumenda", "atque", "doloremque", 
    "nobis", "voluptatem", "quidem", "esse"
  )
  
  latin_suffixes <- c(
    "us", "is", "um", "ae", "am", "ibus", "i", "o"
  )
  
  # Convertir el texto a min√∫sculas para hacer la comparaci√≥n insensible a may√∫sculas/min√∫sculas
  text_lower <- tolower(as.character(text))
  
  # Verificar si alguna palabra clave aparece en el texto (vectorizado)
  has_keywords <- sapply(text_lower, function(txt) {
    any(sapply(latin_keywords, function(kw) grepl(kw, txt)))
  })
  
  # Verificar si el texto contiene sufijos t√≠picos del lat√≠n (vectorizado)
  has_suffixes <- sapply(text_lower, function(txt) {
    any(sapply(latin_suffixes, function(suffix) grepl(paste0("\\b\\w*", suffix, "\\b"), txt)))
  })
  
  # Combinar las condiciones (vectorizado)
  return(has_keywords | has_suffixes)
}
```

```{r}
is_latin("Nulla ullam quo iure repudiandae.")
```
- Clasificaci√≥n de spam valores como lorem ipsum
```{r}
Copia_Datos_Limpios <- Copia_Datos_Limpios %>%
  mutate(
    spam_verified = case_when(
      spam_verified == "ham" & is_latin(review_text) ~ "spam", # Marcar como spam si es lat√≠n
      TRUE ~ spam_verified # Mantener el valor original si no se cumplen las condiciones
    )
  )
```

